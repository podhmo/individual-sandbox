#[python][csv][csvresumable]CSVを消費する処理を再開可能にしたい

CSVを消費する処理を再開可能にしたいという気持ちになりました。具体的には、１つ１つの処理にそこそこ時間が掛かる(30秒から1分)ものをそこそこ多く(10000件くらい)処理しないといけないことがあったのですが。DBとか用意したり使ったりするの面倒だなと思ったときのことです。

## CSVを消費したい(再開したい)

例えば以下の様なイメージです(実際の処理とは異なります)。

input.csv

```csv
id,x,y
1,10,20
2,100,100
```

このようなcsvがあって、これらの各行に対して処理を行う(例えば和を求める)のですが。途中で再開したいという感じです。

output.csv

```csv
id,v
1,30 // 本当は結構重たい
<-- このあたりで止めたい(再開したい)
2,200
```

実際、重いと言っても計算的なものではなく主に帯域制限的なものが原因です。なので並列化とかほぼ意味がない状態なのですが。途中で失敗したら辛いという感じになります。

随時終わるたびに書き出していき、終わったところまで入力を削るみたいな作業をしても良いのですがだるい。

## csvresumable

まぁそんなわけでだるかったので。ちょっとした[ライブラリ](https://github.com/podhmo/csvresumable)を作ることにしました(まだ開発途中なのでAPIの変更は普通にあると思います)。具体的には以下の様な形で動きます。

- 通常のCSVのDictReaderと同様に動く
- どこまで終わったのかを別途記録する(history.csv)
- (再開時には、記録していたところまでの入力はスキップする)

状態など管理するのは面倒だったので、完全にinsertだけで済むようにしました。

例えば上の例で言えば、処理の途中で止めたいということは

```csv
id,x,y
1,10,20
<-- ここで止めたい
2,100,100
```

以下の様な履歴(history.csv)を用意し(csvである必要はない)

```csv
id
1
```

再開(resume)の際はこれとzipしたiterator(概念上)に対して処理を行えば良いということになります。

ちなみに、pandasなどのinterfaceを用意しなかった理由は、そもそも計算や集計が目的ではなかったためです。単なる情報をくれるevent streamとしてCSVがあれば良いというだけだったので(つまりCSVである理由も特にありません)。

### 実際の利用例

実際以下の様な形でかけます。

```python
```
